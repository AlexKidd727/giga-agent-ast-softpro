import os
import json
import logging
from typing import Dict, Optional, Any
from openai import OpenAI
from langchain.chat_models import init_chat_model
from langchain.embeddings import init_embeddings
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

logger = logging.getLogger(__name__)

from giga_agent.utils.env import load_project_env
from giga_agent.utils.gigachat_modes import get_gigachat_mode_manager

GIGACHAT_PROVIDER = "gigachat:"

load_project_env()


def get_agent_env(tag: str = None):
    if tag is None:
        return "GIGA_AGENT_LLM"
    else:
        return f"GIGA_AGENT_LLM_{tag.upper()}"


class OpenAIGigaChatWrapper:
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞, –∏–º–∏—Ç–∏—Ä—É—é—â–∞—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å LangChain"""
    
    def __init__(self, model: str, api_key: str, base_url: str, **kwargs):
        self.model = model
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        self._model_name = f"GigaChat/{model}"
        self._bound_kwargs = {}
        self._config = {}
    
    def invoke(self, messages, **kwargs):
        """–ò–º–∏—Ç–∏—Ä—É–µ—Ç –º–µ—Ç–æ–¥ invoke –∏–∑ LangChain"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç OpenAI
        openai_messages = self._convert_messages_to_openai(messages)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º kwargs —Å –ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        final_kwargs = {**self._bound_kwargs, **kwargs}
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–∏–≤—è–∑–∞–Ω—ã
        if hasattr(self, '_tools') and self._tools:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç OpenAI
            tools = []
            for tool in self._tools:
                # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ —Å–ª–æ–≤–∞—Ä—å (–∏–∑ tool_client.get_tools())
                if isinstance(tool, dict):
                    tool_def = {
                        "type": "function",
                        "function": tool
                    }
                    tools.append(tool_def)
                # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—ä–µ–∫—Ç —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏
                elif hasattr(tool, 'name') and hasattr(tool, 'description'):
                    tool_def = {
                        "type": "function",
                        "function": {
                            "name": tool.name,
                            "description": tool.description,
                        }
                    }
                    # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –µ—Å–ª–∏ –µ—Å—Ç—å
                    if hasattr(tool, 'args_schema'):
                        tool_def["function"]["parameters"] = tool.args_schema.model_json_schema()
                    tools.append(tool_def)
            
            if tools:
                final_kwargs["tools"] = tools
                final_kwargs["tool_choice"] = "auto"
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        print(f"üîç OpenAI API –∑–∞–ø—Ä–æ—Å:")
        print(f"  –ú–æ–¥–µ–ª—å: {self._model_name}")
        print(f"  –°–æ–æ–±—â–µ–Ω–∏—è: {len(openai_messages)}")
        print(f"  –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã: {len(final_kwargs.get('tools', []))}")
        if 'tools' in final_kwargs:
            for i, tool in enumerate(final_kwargs['tools']):
                print(f"    {i+1}. {tool.get('function', {}).get('name', 'unknown')}")
        
        response = self.client.chat.completions.create(
            model=self._model_name,
            messages=openai_messages,
            **final_kwargs
        )
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç LangChain –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        return self._convert_response_to_langchain(response)
    
    def _convert_messages_to_openai(self, messages):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç LangChain —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç OpenAI"""
        openai_messages = []
        system_messages = []
        
        # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞
        if isinstance(messages, str):
            return [{"role": "user", "content": messages}]
        
        # –ï—Å–ª–∏ —ç—Ç–æ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if not isinstance(messages, (list, tuple)):
            messages = [messages]
        
        for message in messages:
            # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ —Å–ª–æ–≤–∞—Ä—å OpenAI
            if isinstance(message, dict):
                if message.get("role") == "system":
                    system_messages.append(message)
                else:
                    openai_messages.append(message)
                continue
            
            # –ï—Å–ª–∏ —ç—Ç–æ LangChain —Å–æ–æ–±—â–µ–Ω–∏–µ
            if hasattr(message, 'content'):
                role = "user"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–æ–ª—å –ø–æ —Ç–∏–ø—É —Å–æ–æ–±—â–µ–Ω–∏—è
                message_type = type(message).__name__.lower()
                if "system" in message_type:
                    role = "system"
                elif "assistant" in message_type:
                    role = "assistant"
                elif "human" in message_type:
                    role = "user"
                elif "ai" in message_type:
                    role = "assistant"
                
                # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ OpenAI
                openai_message = {
                    "role": role,
                    "content": message.content
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º tool_calls –µ—Å–ª–∏ –µ—Å—Ç—å
                if hasattr(message, 'tool_calls') and message.tool_calls:
                    openai_message["tool_calls"] = message.tool_calls
                
                # –î–æ–±–∞–≤–ª—è–µ–º tool_call_id –µ—Å–ª–∏ –µ—Å—Ç—å
                if hasattr(message, 'tool_call_id') and message.tool_call_id:
                    openai_message["tool_call_id"] = message.tool_call_id
                
                # –†–∞–∑–¥–µ–ª—è–µ–º system –∏ –æ–±—ã—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                if role == "system":
                    system_messages.append(openai_message)
                else:
                    openai_messages.append(openai_message)
            else:
                # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø, –ø—Ä–æ–±—É–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                openai_messages.append({
                    "role": "user",
                    "content": str(message)
                })
        
        # System —Å–æ–æ–±—â–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–µ—Ä–≤—ã–º–∏
        return system_messages + openai_messages
    
    def _convert_response_to_langchain(self, response):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç OpenAI –≤ —Ñ–æ—Ä–º–∞—Ç LangChain"""
        # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –æ—Ç–≤–µ—Ç OpenAI, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not hasattr(response, 'choices') or not response.choices:
            return response
        
        message = response.choices[0].message
        
        # –°–æ–∑–¥–∞–µ–º –Ω–∞—Å—Ç–æ—è—â–∏–π AIMessage –∏–∑ LangChain
        if hasattr(message, 'tool_calls') and message.tool_calls:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º tool_calls –≤ —Ñ–æ—Ä–º–∞—Ç LangChain
            tool_calls = []
            for tool_call in message.tool_calls:
                try:
                    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
                    args = json.loads(tool_call.function.arguments) if tool_call.function.arguments else {}
                except (json.JSONDecodeError, AttributeError):
                    args = {}
                
                tool_calls.append({
                    "name": tool_call.function.name,
                    "args": args,
                    "id": tool_call.id
                })
            
            return AIMessage(
                content=message.content or "",
                tool_calls=tool_calls
            )
        else:
            return AIMessage(
                content=message.content or ""
            )
    
    def _safe_serialize(self, obj: Any) -> Any:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è JSON"""
        try:
            # –ü—Ä–æ–±—É–µ–º —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å
            json.dumps(obj)
            return obj
        except (TypeError, ValueError):
            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
            if hasattr(obj, 'content'):
                return obj.content
            elif hasattr(obj, '__dict__'):
                return str(obj)
            else:
                return str(obj)
    
    def __call__(self, messages, **kwargs):
        """–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—ã–∑–æ–≤ –∫–∞–∫ —Ñ—É–Ω–∫—Ü–∏–∏"""
        response = self.invoke(messages, **kwargs)
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º LangChain —Å–æ–æ–±—â–µ–Ω–∏–µ
        return response
    
    def bind(self, **kwargs):
        """–ò–º–∏—Ç–∏—Ä—É–µ—Ç –º–µ—Ç–æ–¥ bind –∏–∑ LangChain - –ø—Ä–∏–≤—è–∑—ã–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã"""
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –æ–±–µ—Ä—Ç–∫—É —Å –ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        new_wrapper = OpenAIGigaChatWrapper(
            model=self.model,
            api_key=self.client.api_key,
            base_url=self.client.base_url
        )
        new_wrapper._bound_kwargs = {**self._bound_kwargs, **kwargs}
        new_wrapper._config = self._config.copy()
        
        # –ö–æ–ø–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        if hasattr(self, '_tools'):
            new_wrapper._tools = self._tools
        if hasattr(self, '_parallel_tool_calls'):
            new_wrapper._parallel_tool_calls = self._parallel_tool_calls
        if hasattr(self, '_tool_kwargs'):
            new_wrapper._tool_kwargs = self._tool_kwargs.copy()
        
        return new_wrapper
    
    def with_config(self, tags=None, **config):
        """–ò–º–∏—Ç–∏—Ä—É–µ—Ç –º–µ—Ç–æ–¥ with_config –∏–∑ LangChain"""
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –æ–±–µ—Ä—Ç–∫—É —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        new_wrapper = OpenAIGigaChatWrapper(
            model=self.model,
            api_key=self.client.api_key,
            base_url=self.client.base_url
        )
        new_wrapper._bound_kwargs = self._bound_kwargs.copy()
        new_wrapper._config = {**self._config, **config}
        if tags:
            new_wrapper._config['tags'] = tags
        
        # –ö–æ–ø–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        if hasattr(self, '_tools'):
            new_wrapper._tools = self._tools
        if hasattr(self, '_parallel_tool_calls'):
            new_wrapper._parallel_tool_calls = self._parallel_tool_calls
        if hasattr(self, '_tool_kwargs'):
            new_wrapper._tool_kwargs = self._tool_kwargs.copy()
        
        return new_wrapper
    
    def bind_tools(self, tools, parallel_tool_calls=False, **kwargs):
        """–ò–º–∏—Ç–∏—Ä—É–µ—Ç –º–µ—Ç–æ–¥ bind_tools –∏–∑ LangChain"""
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –æ–±–µ—Ä—Ç–∫—É —Å –ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏
        new_wrapper = OpenAIGigaChatWrapper(
            model=self.model,
            api_key=self.client.api_key,
            base_url=self.client.base_url
        )
        new_wrapper._bound_kwargs = self._bound_kwargs.copy()
        new_wrapper._config = self._config.copy()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        new_wrapper._tools = tools
        new_wrapper._parallel_tool_calls = parallel_tool_calls
        new_wrapper._tool_kwargs = kwargs
        
        return new_wrapper


def load_gigachat(tag: str = None, is_main: bool = False):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç GigaChat —á–µ—Ä–µ–∑ OpenAI –∫–ª–∏–µ–Ω—Ç"""
    llm_str = os.getenv(get_agent_env(tag))
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    if is_main:
        api_key = os.getenv("MAIN_GIGACHAT_CREDENTIALS")
        base_url = os.getenv("MAIN_GIGACHAT_BASE_URL", "https://foundation-models.api.cloud.ru/v1")
    else:
        api_key = os.getenv("GIGACHAT_CREDENTIALS")
        base_url = os.getenv("GIGACHAT_BASE_URL", "https://foundation-models.api.cloud.ru/v1")
    
    # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    original_model = llm_str[len(GIGACHAT_PROVIDER):]
    
    # –ü–æ–ª—É—á–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä —Ä–µ–∂–∏–º–æ–≤
    mode_manager = get_gigachat_mode_manager()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
    model_name = mode_manager.get_model_name(original_model)
    
    # –°–æ–∑–¥–∞–µ–º –æ–±–µ—Ä—Ç–∫—É OpenAI –∫–ª–∏–µ–Ω—Ç–∞
    return OpenAIGigaChatWrapper(
        model=model_name,
        api_key=api_key,
        base_url=base_url
    )


def load_gigachat_embeddings():
    """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è embeddings - –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ"""
    # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å embeddings —á–µ—Ä–µ–∑ OpenAI API –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    raise NotImplementedError("Embeddings —á–µ—Ä–µ–∑ OpenAI API –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã")


def is_llm_gigachat(tag: str = None):
    llm_str = os.getenv(get_agent_env(tag))
    return llm_str.startswith(GIGACHAT_PROVIDER)


# Singletons cache
_LLM_SINGLETONS: Dict[str, object] = {}
_EMBEDDINGS_SINGLETON: Optional[object] = None


def load_llm(tag: str = None, is_main: bool = False):
    env_key = get_agent_env(tag)
    singleton_key = env_key
    if is_main:
        singleton_key = "MAIN_" + singleton_key
    if singleton_key in _LLM_SINGLETONS:
        return _LLM_SINGLETONS[singleton_key]

    llm_str = os.getenv(env_key)
    if llm_str is None:
        raise RuntimeError(f"{env_key} is empty! Fill it with your model")

    if llm_str.startswith(GIGACHAT_PROVIDER):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à—É –æ–±–µ—Ä—Ç–∫—É OpenAIGigaChatWrapper –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        try:
            from langchain_gigachat import ChatGigaChat
            llm = ChatGigaChat(
                model=llm_str[len(GIGACHAT_PROVIDER):],
                credentials=os.getenv("MAIN_GIGACHAT_CREDENTIALS" if is_main else "GIGACHAT_CREDENTIALS"),
                scope="GIGACHAT_API_PERS",
                verify_ssl_certs=False
            )
        except ImportError:
            # Fallback –Ω–∞ –Ω–∞—à—É –æ–±–µ—Ä—Ç–∫—É –µ—Å–ª–∏ langchain_gigachat –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
            logger.warning("langchain_gigachat –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º OpenAIGigaChatWrapper")
            model_name = llm_str[len(GIGACHAT_PROVIDER):]
            api_key = os.getenv("MAIN_GIGACHAT_CREDENTIALS" if is_main else "GIGACHAT_CREDENTIALS")
            base_url = os.getenv("GIGACHAT_BASE_URL", "https://gigachat.devices.sberbank.ru/api/v1")
            llm = OpenAIGigaChatWrapper(
                model=model_name,
                api_key=api_key,
                base_url=base_url
            )
    else:
        llm = init_chat_model(llm_str)

    _LLM_SINGLETONS[singleton_key] = llm
    return llm


def load_embeddings():
    global _EMBEDDINGS_SINGLETON

    if _EMBEDDINGS_SINGLETON is not None:
        return _EMBEDDINGS_SINGLETON

    emb_str = os.getenv("GIGA_AGENT_EMBEDDINGS")
    if emb_str is None:
        raise RuntimeError("GIGA_AGENT_EMBEDDINGS is empty! Fill it with your model")

    if emb_str.startswith(GIGACHAT_PROVIDER):
        embeddings = load_gigachat_embeddings()
    else:
        embeddings = init_embeddings(emb_str)

    _EMBEDDINGS_SINGLETON = embeddings
    return embeddings


def is_llm_image_inline():
    llm_str = os.getenv("GIGA_AGENT_LLM")
    if llm_str is None:
        raise RuntimeError("GIGA_AGENT_LLM is empty! Fill it with your model")
    return llm_str.startswith(GIGACHAT_PROVIDER)